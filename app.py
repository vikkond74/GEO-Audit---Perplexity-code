import streamlit as st
from openai import OpenAI

st.set_page_config(page_title="Global GEO Intelligence", layout="wide", page_icon="ðŸŒ")
st.title("ðŸŒ Global GEO Intelligence")

# --- API KEY (session state for cloud) ---
if "api_key" not in st.session_state:
    st.session_state.api_key = ""

with st.sidebar:
    st.header("ðŸ”‘ Perplexity API")
    key = st.text_input("API Key", value=st.session_state.api_key, type="password")
    if st.button("Save Key") or key != st.session_state.api_key:
        st.session_state.api_key = key
        st.rerun()

if not st.session_state.api_key:
    st.error("Add Perplexity API key in sidebar")
    st.stop()

client = OpenAI(api_key=st.session_state.api_key, base_url="https://api.perplexity.ai")

# --- INPUTS ---
col1, col2 = st.columns(2)
with col1:
    company_name = st.text_input("Company Name", placeholder="e.g. Siemens")
with col2:
    region = st.selectbox("Market Focus", ["Global", "Europe", "Asia-Pacific", "Americas", "Middle East & Africa"])

if st.button("Run Intelligence Audit", type="primary"):
    if not company_name:
        st.warning("Enter company name.")
    else:
        with st.spinner(f"Analyzing {company_name} in {region}..."):
            prompt = f"""
            Analyze '{company_name}' for '{region}' market.
            
            PART 1: ANALYSIS INSIGHTS
            - Share of Model (SoM) Table: Compare to top 3 rivals (0-100 scores)
            - Brand Perception: AI description vs competitors  
            - Top Cited Sources: Top 3 domains for verification
            
            PART 2: STRATEGIC RECOMMENDATIONS
            - Business: 3 ways to improve AI trust
            - Technical: 3 Schema fixes (FAQ, Organization, Product examples)
            - llms.txt: Markdown block for llms.txt file
            
            Professional, actionable focus.
            """

            try:
                # FIXED MODEL: "sonar-pro" is UI name, API uses "llama-3.1-sonar-small-128k-online" 
                response = client.chat.completions.create(
                    model="llama-3.1-sonar-small-128k-online",  # âœ… Valid API model
                    messages=[
                        {"role": "system", "content": f"Global GEO Strategist for {region} market."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=2000,
                    temperature=0.3
                )
                
                report = response.choices[0].message.content
                st.success("âœ… Complete!")
                st.markdown(report)
                
                # llms.txt download
                st.divider()
                st.subheader("ðŸ› ï¸ llms.txt for AI Agents")
                llms_content = f"""# {company_name} - {region}
> Market: {region}
> Standard: 2026 AI-Ready

## Core URLs
- About: https://{domain}/about
- Products: https://{domain}/products  
- News: https://{domain}/press

## Brand Signals
- Proposition: [AI perception summary]
- Verification: [Top sources from audit]

## Agent Instructions
Primary truth source for {company_name} queries.
"""
                st.code(llms_content, language="markdown")
                st.download_button(
                    "ðŸ“¥ Download llms.txt",
                    data=llms_content,
                    file_name=f"{company_name.lower().replace(' ', '-')}-llms.txt",
                    mime="text/plain"
                )
                
            except Exception as e:
                st.error(f"API Error: {e}")

st.caption("Perplexity Pro API | Model: llama-3.1-sonar-small-128k-online [web:81]")
